{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the Python code for constructing a boosted decision tree model with a 4D input and a 1D output (using y1 for the regression task). \n",
    "# The data is split into training, validation, and testing sets in a 60%, 20%, and 20% ratio, respectively. \n",
    "# The x1 feature and the target variable y1 are transformed using the provided functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Define the transformation functions\n",
    "def x_scale(x, p=7.5):\n",
    "    return 1/p * np.log(1 + x * (np.exp(p) - 1))\n",
    "\n",
    "\n",
    "#def y_scale(y):\n",
    " #   return np.log(1 + y) if y >= 0 else -np.log(1 - y)\n",
    "\n",
    "def y_scale(y):\n",
    "    return np.where(y >= 0, np.log(1 + y), -np.log(1 - y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Apply transformations\n",
    "df['x1'] = x_scale(df['x1'])\n",
    "#df['y1'] = df['y1'].apply(y_scale)\n",
    "df['y1'] = y_scale(df['y1'])\n",
    "\n",
    "# Splitting the data into input features and target variable\n",
    "X = df[['x1', 'x2', 'x3', 'x4']]\n",
    "y = df['y1']  # I am are choosing y1 for the regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training, validation, and testing sets (60%, 20%, 20%)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=4, n_estimators=150)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GradientBoostingRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">?<span>Documentation for GradientBoostingRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GradientBoostingRegressor(max_depth=4, n_estimators=150)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(max_depth=4, n_estimators=150)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = GradientBoostingRegressor(\n",
    "    n_estimators=150,  # number of boosting stages to be run\n",
    "    max_depth= 4,  # maximum depth of each tree\n",
    "    min_samples_split=2,  # minimum samples required to split an internal node\n",
    "    min_samples_leaf=1  # minimum samples required to be at a leaf node\n",
    ")\n",
    "\n",
    "# Training the modelmodel = GradientBoostingRegressor(\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.9851\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Test set accuracy: {:.4f}\".format(model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 0.19552328445882264\n",
      "Test MSE: 0.19631137202295482\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Validation MSE: {val_mse}\")\n",
    "\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "print(f\"Test MSE: {test_mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(features, feature_importance)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance in Boosted Decision Tree Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "#will use k as 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indices: [     1      2      4 ... 999996 999997 999998]\n",
      "Test indices: [     0      3      8 ... 999980 999988 999999]\n",
      "Train data:\n",
      "               x1        x2        x3        x4        y1          y2\n",
      "1       0.000469  0.495374  0.961166  0.213009  4.270934  -79.824819\n",
      "2       0.000546  0.045435  0.109773  0.292582  4.332126  -77.123068\n",
      "4       0.000698  0.606808  0.861252  0.604051 -3.335759   26.709271\n",
      "5       0.000753  0.623257  0.662706  0.978168 -4.338092   80.145387\n",
      "6       0.000783  0.333943  0.772378  0.015987  5.057732 -172.882078\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "999994  0.708763  0.648808  0.003329  0.923629 -2.644603    6.653641\n",
      "999995  0.708798  0.017806  0.594506  0.500338  5.961519  -64.342897\n",
      "999996  0.708874  0.100856  0.503775  0.872723  4.512761  -27.617936\n",
      "999997  0.708960  0.154529  0.147156  0.431693  4.060644  -21.132118\n",
      "999998  0.708984  0.282299  0.888741  0.684521  3.241564   -9.313387\n",
      "\n",
      "[900000 rows x 6 columns]\n",
      "Test data:\n",
      "               x1        x2        x3        x4        y1         y2\n",
      "0       0.000355  0.531085  0.855767  0.611623  1.786892  -6.548192\n",
      "3       0.000568  0.064068  0.774908  0.820672  4.545383 -96.298052\n",
      "8       0.000954  0.353791  0.123150  0.564828  2.897988 -14.425029\n",
      "9       0.000967  0.360358  0.215959  0.578031  3.235969 -22.818801\n",
      "10      0.001191  0.756153  0.937011  0.409760 -4.156417  62.865983\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "999958  0.705833  0.884704  0.688157  0.747984 -4.340169  27.311485\n",
      "999970  0.706583  0.682784  0.191575  0.348391 -3.026918   7.701981\n",
      "999980  0.707435  0.753120  0.896825  0.675649 -3.509727  10.671805\n",
      "999988  0.708065  0.273446  0.179030  0.313159  3.331642 -10.009190\n",
      "999999  0.709006  0.958548  0.037049  0.193708 -5.189604  74.920107\n",
      "\n",
      "[100000 rows x 6 columns]\n",
      "Train indices: [     0      1      2 ... 999997 999998 999999]\n",
      "Test indices: [    17     24     33 ... 999982 999989 999991]\n",
      "Train data:\n",
      "               x1        x2        x3        x4        y1         y2\n",
      "0       0.000355  0.531085  0.855767  0.611623  1.786892  -6.548192\n",
      "1       0.000469  0.495374  0.961166  0.213009  4.270934 -79.824819\n",
      "2       0.000546  0.045435  0.109773  0.292582  4.332126 -77.123068\n",
      "3       0.000568  0.064068  0.774908  0.820672  4.545383 -96.298052\n",
      "4       0.000698  0.606808  0.861252  0.604051 -3.335759  26.709271\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "999995  0.708798  0.017806  0.594506  0.500338  5.961519 -64.342897\n",
      "999996  0.708874  0.100856  0.503775  0.872723  4.512761 -27.617936\n",
      "999997  0.708960  0.154529  0.147156  0.431693  4.060644 -21.132118\n",
      "999998  0.708984  0.282299  0.888741  0.684521  3.241564  -9.313387\n",
      "999999  0.709006  0.958548  0.037049  0.193708 -5.189604  74.920107\n",
      "\n",
      "[900000 rows x 6 columns]\n",
      "Test data:\n",
      "               x1        x2        x3        x4        y1          y2\n",
      "17      0.001961  0.295326  0.012043  0.691796  2.952464  -13.789152\n",
      "24      0.002560  0.375069  0.141381  0.423419  3.147309  -21.090402\n",
      "33      0.003222  0.762009  0.331149  0.023982 -4.201541   66.703174\n",
      "45      0.003649  0.942210  0.915425  0.215401 -4.219718   68.088117\n",
      "47      0.003704  0.249914  0.995821  0.733168  4.727041 -117.892712\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "999956  0.705746  0.885008  0.754110  0.602875 -4.364942   26.199863\n",
      "999964  0.706117  0.249991  0.776397  0.542083  3.428680  -11.581395\n",
      "999982  0.707514  0.499913  0.898037  0.691366 -0.469868   -0.240789\n",
      "999989  0.708136  0.568018  0.144561  0.530467 -1.923008    2.783467\n",
      "999991  0.708336  0.688833  0.180411  0.250435 -3.077584    7.998720\n",
      "\n",
      "[100000 rows x 6 columns]\n",
      "Train indices: [     0      1      2 ... 999997 999998 999999]\n",
      "Test indices: [    13     14     20 ... 999981 999986 999994]\n",
      "Train data:\n",
      "               x1        x2        x3        x4        y1         y2\n",
      "0       0.000355  0.531085  0.855767  0.611623  1.786892  -6.548192\n",
      "1       0.000469  0.495374  0.961166  0.213009  4.270934 -79.824819\n",
      "2       0.000546  0.045435  0.109773  0.292582  4.332126 -77.123068\n",
      "3       0.000568  0.064068  0.774908  0.820672  4.545383 -96.298052\n",
      "4       0.000698  0.606808  0.861252  0.604051 -3.335759  26.709271\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "999995  0.708798  0.017806  0.594506  0.500338  5.961519 -64.342897\n",
      "999996  0.708874  0.100856  0.503775  0.872723  4.512761 -27.617936\n",
      "999997  0.708960  0.154529  0.147156  0.431693  4.060644 -21.132118\n",
      "999998  0.708984  0.282299  0.888741  0.684521  3.241564  -9.313387\n",
      "999999  0.709006  0.958548  0.037049  0.193708 -5.189604  74.920107\n",
      "\n",
      "[900000 rows x 6 columns]\n",
      "Test data:\n",
      "               x1        x2        x3        x4        y1         y2\n",
      "13      0.001522  0.451437  0.361680  0.235776  3.597597 -38.042903\n",
      "14      0.001561  0.948907  0.657583  0.033814 -4.154851  63.684226\n",
      "20      0.002115  0.037347  0.022162  0.822316  3.991611 -53.837802\n",
      "23      0.002528  0.541403  0.435228  0.382830 -2.631184  13.093859\n",
      "35      0.003277  0.132019  0.400357  0.855896  4.472424 -88.420359\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "999950  0.705388  0.129432  0.133986  0.036226  4.190572 -27.435481\n",
      "999959  0.705937  0.789436  0.126217  0.809098 -3.602788  15.966004\n",
      "999981  0.707449  0.897826  0.537242  0.790151 -4.430721  32.360483\n",
      "999986  0.707723  0.805863  0.758081  0.860203 -3.781899  15.739985\n",
      "999994  0.708763  0.648808  0.003329  0.923629 -2.644603   6.653641\n",
      "\n",
      "[100000 rows x 6 columns]\n",
      "Train indices: [     0      1      2 ... 999997 999998 999999]\n",
      "Test indices: [    15     18     31 ... 999949 999978 999990]\n",
      "Train data:\n",
      "               x1        x2        x3        x4        y1         y2\n",
      "0       0.000355  0.531085  0.855767  0.611623  1.786892  -6.548192\n",
      "1       0.000469  0.495374  0.961166  0.213009  4.270934 -79.824819\n",
      "2       0.000546  0.045435  0.109773  0.292582  4.332126 -77.123068\n",
      "3       0.000568  0.064068  0.774908  0.820672  4.545383 -96.298052\n",
      "4       0.000698  0.606808  0.861252  0.604051 -3.335759  26.709271\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "999995  0.708798  0.017806  0.594506  0.500338  5.961519 -64.342897\n",
      "999996  0.708874  0.100856  0.503775  0.872723  4.512761 -27.617936\n",
      "999997  0.708960  0.154529  0.147156  0.431693  4.060644 -21.132118\n",
      "999998  0.708984  0.282299  0.888741  0.684521  3.241564  -9.313387\n",
      "999999  0.709006  0.958548  0.037049  0.193708 -5.189604  74.920107\n",
      "\n",
      "[900000 rows x 6 columns]\n",
      "Test data:\n",
      "               x1        x2        x3        x4        y1          y2\n",
      "15      0.001685  0.738349  0.674643  0.211020 -4.018589   54.199172\n",
      "18      0.002039  0.633067  0.777766  0.198543 -1.754080    0.935566\n",
      "31      0.003124  0.120988  0.784288  0.599205  4.792517 -124.763345\n",
      "39      0.003450  0.153097  0.453156  0.110712  4.964178 -150.778290\n",
      "44      0.003645  0.302512  0.031833  0.473016  3.528200  -31.416861\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "999932  0.704207  0.061329  0.837971  0.975074  4.958691  -35.155390\n",
      "999933  0.704406  0.437141  0.989095  0.855829  1.932917   -2.319025\n",
      "999949  0.705265  0.047446  0.023045  0.895324  5.225442  -32.723432\n",
      "999978  0.707415  0.578985  0.612618  0.542181 -2.219319    2.772242\n",
      "999990  0.708210  0.916918  0.698042  0.807800 -4.646232   36.158277\n",
      "\n",
      "[100000 rows x 6 columns]\n",
      "Train indices: [     0      1      3 ... 999997 999998 999999]\n",
      "Test indices: [     2     16     21 ... 999972 999974 999985]\n",
      "Train data:\n",
      "               x1        x2        x3        x4        y1         y2\n",
      "0       0.000355  0.531085  0.855767  0.611623  1.786892  -6.548192\n",
      "1       0.000469  0.495374  0.961166  0.213009  4.270934 -79.824819\n",
      "3       0.000568  0.064068  0.774908  0.820672  4.545383 -96.298052\n",
      "4       0.000698  0.606808  0.861252  0.604051 -3.335759  26.709271\n",
      "5       0.000753  0.623257  0.662706  0.978168 -4.338092  80.145387\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "999995  0.708798  0.017806  0.594506  0.500338  5.961519 -64.342897\n",
      "999996  0.708874  0.100856  0.503775  0.872723  4.512761 -27.617936\n",
      "999997  0.708960  0.154529  0.147156  0.431693  4.060644 -21.132118\n",
      "999998  0.708984  0.282299  0.888741  0.684521  3.241564  -9.313387\n",
      "999999  0.709006  0.958548  0.037049  0.193708 -5.189604  74.920107\n",
      "\n",
      "[900000 rows x 6 columns]\n",
      "Test data:\n",
      "               x1        x2        x3        x4        y1          y2\n",
      "2       0.000546  0.045435  0.109773  0.292582  4.332126  -77.123068\n",
      "16      0.001897  0.657808  0.236718  0.788227 -4.782371  128.255309\n",
      "21      0.002154  0.256016  0.801468  0.140472  5.070051 -171.759062\n",
      "26      0.002606  0.085500  0.552939  0.679909  4.586457 -100.162590\n",
      "29      0.002909  0.558630  0.150416  0.077619 -2.792927   15.394620\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "999961  0.705956  0.235003  0.343155  0.249305  3.528742  -12.971685\n",
      "999968  0.706317  0.552171  0.474713  0.536201 -1.800545    1.924185\n",
      "999972  0.706726  0.643885  0.446952  0.557834 -2.765630    5.629524\n",
      "999974  0.706787  0.449720  0.322189  0.113574  1.706440   -1.985723\n",
      "999985  0.707720  0.931517  0.283964  0.486682 -4.783092   47.756159\n",
      "\n",
      "[100000 rows x 6 columns]\n",
      "Train indices: [     0      2      3 ... 999997 999998 999999]\n",
      "Test indices: [     1      4      7 ... 999935 999962 999996]\n",
      "Train data:\n",
      "               x1        x2        x3        x4        y1          y2\n",
      "0       0.000355  0.531085  0.855767  0.611623  1.786892   -6.548192\n",
      "2       0.000546  0.045435  0.109773  0.292582  4.332126  -77.123068\n",
      "3       0.000568  0.064068  0.774908  0.820672  4.545383  -96.298052\n",
      "5       0.000753  0.623257  0.662706  0.978168 -4.338092   80.145387\n",
      "6       0.000783  0.333943  0.772378  0.015987  5.057732 -172.882078\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "999994  0.708763  0.648808  0.003329  0.923629 -2.644603    6.653641\n",
      "999995  0.708798  0.017806  0.594506  0.500338  5.961519  -64.342897\n",
      "999997  0.708960  0.154529  0.147156  0.431693  4.060644  -21.132118\n",
      "999998  0.708984  0.282299  0.888741  0.684521  3.241564   -9.313387\n",
      "999999  0.709006  0.958548  0.037049  0.193708 -5.189604   74.920107\n",
      "\n",
      "[900000 rows x 6 columns]\n",
      "Test data:\n",
      "               x1        x2        x3        x4        y1          y2\n",
      "1       0.000469  0.495374  0.961166  0.213009  4.270934  -79.824819\n",
      "4       0.000698  0.606808  0.861252  0.604051 -3.335759   26.709271\n",
      "7       0.000916  0.160388  0.720130  0.155221  5.072598 -169.666840\n",
      "11      0.001486  0.327033  0.768450  0.466342  4.579092 -102.200587\n",
      "32      0.003154  0.031684  0.903891  0.707784  4.374325  -81.347895\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "999902  0.701873  0.798565  0.772550  0.926111 -3.731889   14.968808\n",
      "999925  0.703114  0.791338  0.655550  0.487291 -3.722421   14.114421\n",
      "999935  0.704426  0.065121  0.632914  0.564749  4.864619  -44.169313\n",
      "999962  0.705995  0.557038  0.016288  0.362359 -1.768771    2.323425\n",
      "999996  0.708874  0.100856  0.503775  0.872723  4.512761  -27.617936\n",
      "\n",
      "[100000 rows x 6 columns]\n",
      "Train indices: [     0      1      2 ... 999997 999998 999999]\n",
      "Test indices: [     6     19     54 ... 999983 999984 999995]\n",
      "Train data:\n",
      "               x1        x2        x3        x4        y1         y2\n",
      "0       0.000355  0.531085  0.855767  0.611623  1.786892  -6.548192\n",
      "1       0.000469  0.495374  0.961166  0.213009  4.270934 -79.824819\n",
      "2       0.000546  0.045435  0.109773  0.292582  4.332126 -77.123068\n",
      "3       0.000568  0.064068  0.774908  0.820672  4.545383 -96.298052\n",
      "4       0.000698  0.606808  0.861252  0.604051 -3.335759  26.709271\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "999994  0.708763  0.648808  0.003329  0.923629 -2.644603   6.653641\n",
      "999996  0.708874  0.100856  0.503775  0.872723  4.512761 -27.617936\n",
      "999997  0.708960  0.154529  0.147156  0.431693  4.060644 -21.132118\n",
      "999998  0.708984  0.282299  0.888741  0.684521  3.241564  -9.313387\n",
      "999999  0.709006  0.958548  0.037049  0.193708 -5.189604  74.920107\n",
      "\n",
      "[900000 rows x 6 columns]\n",
      "Test data:\n",
      "               x1        x2        x3        x4        y1          y2\n",
      "6       0.000783  0.333943  0.772378  0.015987  5.057732 -172.882078\n",
      "19      0.002063  0.958534  0.036956  0.414688 -4.648349  109.098645\n",
      "54      0.004109  0.462794  0.990294  0.831055  3.333818  -29.062117\n",
      "69      0.005048  0.476416  0.458692  0.226691  3.588645  -38.975660\n",
      "71      0.005212  0.356353  0.709661  0.972484  3.777103  -43.515624\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "999966  0.706253  0.009971  0.838569  0.951593  6.285327  128.275822\n",
      "999967  0.706288  0.903319  0.631480  0.951446 -4.482575   33.546158\n",
      "999983  0.707556  0.492459  0.467415  0.716900  0.894488   -0.025711\n",
      "999984  0.707611  0.032892  0.577116  0.991919  5.503698  -27.644387\n",
      "999995  0.708798  0.017806  0.594506  0.500338  5.961519  -64.342897\n",
      "\n",
      "[100000 rows x 6 columns]\n",
      "Train indices: [     0      1      2 ... 999996 999997 999999]\n",
      "Test indices: [    22     28     30 ... 999977 999987 999998]\n",
      "Train data:\n",
      "               x1        x2        x3        x4        y1         y2\n",
      "0       0.000355  0.531085  0.855767  0.611623  1.786892  -6.548192\n",
      "1       0.000469  0.495374  0.961166  0.213009  4.270934 -79.824819\n",
      "2       0.000546  0.045435  0.109773  0.292582  4.332126 -77.123068\n",
      "3       0.000568  0.064068  0.774908  0.820672  4.545383 -96.298052\n",
      "4       0.000698  0.606808  0.861252  0.604051 -3.335759  26.709271\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "999994  0.708763  0.648808  0.003329  0.923629 -2.644603   6.653641\n",
      "999995  0.708798  0.017806  0.594506  0.500338  5.961519 -64.342897\n",
      "999996  0.708874  0.100856  0.503775  0.872723  4.512761 -27.617936\n",
      "999997  0.708960  0.154529  0.147156  0.431693  4.060644 -21.132118\n",
      "999999  0.709006  0.958548  0.037049  0.193708 -5.189604  74.920107\n",
      "\n",
      "[900000 rows x 6 columns]\n",
      "Test data:\n",
      "               x1        x2        x3        x4        y1          y2\n",
      "22      0.002445  0.485456  0.987229  0.198395  4.378959  -89.350150\n",
      "28      0.002880  0.785866  0.590762  0.047545 -4.070553   57.038939\n",
      "30      0.003083  0.383887  0.016186  0.573025 -2.563954   17.640093\n",
      "41      0.003588  0.950493  0.927890  0.907525 -4.470511   89.231231\n",
      "59      0.004534  0.646588  0.280074  0.808084 -4.705576  119.288011\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "999975  0.706975  0.623368  0.625457  0.648737 -2.623083    4.579699\n",
      "999976  0.707044  0.280678  0.598686  0.995851  3.338657   -8.262379\n",
      "999977  0.707231  0.203127  0.893708  0.908588  3.743401  -14.284742\n",
      "999987  0.707753  0.835162  0.450720  0.083601 -4.000162   19.506934\n",
      "999998  0.708984  0.282299  0.888741  0.684521  3.241564   -9.313387\n",
      "\n",
      "[100000 rows x 6 columns]\n",
      "Train indices: [     0      1      2 ... 999997 999998 999999]\n",
      "Test indices: [    12     25     58 ... 999954 999973 999979]\n",
      "Train data:\n",
      "               x1        x2        x3        x4        y1         y2\n",
      "0       0.000355  0.531085  0.855767  0.611623  1.786892  -6.548192\n",
      "1       0.000469  0.495374  0.961166  0.213009  4.270934 -79.824819\n",
      "2       0.000546  0.045435  0.109773  0.292582  4.332126 -77.123068\n",
      "3       0.000568  0.064068  0.774908  0.820672  4.545383 -96.298052\n",
      "4       0.000698  0.606808  0.861252  0.604051 -3.335759  26.709271\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "999995  0.708798  0.017806  0.594506  0.500338  5.961519 -64.342897\n",
      "999996  0.708874  0.100856  0.503775  0.872723  4.512761 -27.617936\n",
      "999997  0.708960  0.154529  0.147156  0.431693  4.060644 -21.132118\n",
      "999998  0.708984  0.282299  0.888741  0.684521  3.241564  -9.313387\n",
      "999999  0.709006  0.958548  0.037049  0.193708 -5.189604  74.920107\n",
      "\n",
      "[900000 rows x 6 columns]\n",
      "Test data:\n",
      "               x1        x2        x3        x4        y1          y2\n",
      "12      0.001522  0.761497  0.835324  0.899482 -4.640075  106.678162\n",
      "25      0.002562  0.677590  0.471720  0.324816 -4.099371   60.923653\n",
      "58      0.004476  0.675830  0.530956  0.665261 -4.430122   87.637896\n",
      "63      0.004859  0.144960  0.122573  0.796137  4.253892  -69.882596\n",
      "72      0.005297  0.657101  0.367400  0.819931 -4.653028  112.401765\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "999931  0.703952  0.577653  0.078566  0.172183 -2.151319    2.981992\n",
      "999940  0.704712  0.463651  0.828999  0.375364  1.197964   -1.741308\n",
      "999954  0.705589  0.879365  0.501471  0.037507 -4.328724   26.321453\n",
      "999973  0.706777  0.883805  0.776110  0.005495 -4.402607   24.564920\n",
      "999979  0.707434  0.092920  0.142454  0.790363  4.606563  -29.279940\n",
      "\n",
      "[100000 rows x 6 columns]\n",
      "Train indices: [     0      1      2 ... 999996 999998 999999]\n",
      "Test indices: [     5     37     40 ... 999992 999993 999997]\n",
      "Train data:\n",
      "               x1        x2        x3        x4        y1         y2\n",
      "0       0.000355  0.531085  0.855767  0.611623  1.786892  -6.548192\n",
      "1       0.000469  0.495374  0.961166  0.213009  4.270934 -79.824819\n",
      "2       0.000546  0.045435  0.109773  0.292582  4.332126 -77.123068\n",
      "3       0.000568  0.064068  0.774908  0.820672  4.545383 -96.298052\n",
      "4       0.000698  0.606808  0.861252  0.604051 -3.335759  26.709271\n",
      "...          ...       ...       ...       ...       ...        ...\n",
      "999994  0.708763  0.648808  0.003329  0.923629 -2.644603   6.653641\n",
      "999995  0.708798  0.017806  0.594506  0.500338  5.961519 -64.342897\n",
      "999996  0.708874  0.100856  0.503775  0.872723  4.512761 -27.617936\n",
      "999998  0.708984  0.282299  0.888741  0.684521  3.241564  -9.313387\n",
      "999999  0.709006  0.958548  0.037049  0.193708 -5.189604  74.920107\n",
      "\n",
      "[900000 rows x 6 columns]\n",
      "Test data:\n",
      "               x1        x2        x3        x4        y1          y2\n",
      "5       0.000753  0.623257  0.662706  0.978168 -4.338092   80.145387\n",
      "37      0.003309  0.089077  0.146557  0.410387  4.486087  -89.966906\n",
      "40      0.003579  0.873647  0.622558  0.907648 -4.837758  131.059393\n",
      "43      0.003630  0.560980  0.494855  0.438731 -3.100746   21.862176\n",
      "75      0.005386  0.288149  0.196315  0.406720  4.156834  -64.811846\n",
      "...          ...       ...       ...       ...       ...         ...\n",
      "999942  0.704865  0.016326  0.447875  0.287502  6.014508  -91.679614\n",
      "999963  0.706034  0.168585  0.096615  0.268672  3.952705  -19.722611\n",
      "999992  0.708482  0.033095  0.189907  0.711423  5.497178  -44.979604\n",
      "999993  0.708651  0.823839  0.732341  0.801733 -3.897740   17.704369\n",
      "999997  0.708960  0.154529  0.147156  0.431693  4.060644  -21.132118\n",
      "\n",
      "[100000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "\n",
    "for train_index, test_index in kfold.split(df):\n",
    "    # Print the indices of the train and test sets\n",
    "    print('Train indices:', train_index)\n",
    "    print('Test indices:', test_index)\n",
    "    \n",
    "    # Print the actual train and test DataFrames\n",
    "    print('Train data:\\n', df.iloc[train_index])\n",
    "    print('Test data:\\n', df.iloc[test_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 30\n",
    "\n",
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "\n",
    "\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_cross_validation(clf, print_model=False):\n",
    "    cv = cross_validate(clf, X, y, scoring='accuracy', cv=3)\n",
    "    scores = ' + '.join(f'{s:.2f}' for s in cv[\"test_score\"])\n",
    "    mean_ = cv[\"test_score\"].mean()\n",
    "    msg = f'Cross-validated accuracy: ({scores}) / 3 = {mean_:.2f}'\n",
    "    \n",
    "    if print_model:\n",
    "        msg = f'{clf}:\\n\\t{msg}\\n'\n",
    "    \n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m clf_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(GradientBoostingRegressor(min_samples_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, min_samples_leaf \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m), param_grid\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m150\u001b[39m]})\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdo_cross_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m, in \u001b[0;36mdo_cross_validation\u001b[1;34m(clf, print_model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_cross_validation\u001b[39m(clf, print_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m----> 2\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m + \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m cv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      4\u001b[0m     mean_ \u001b[38;5;241m=\u001b[39m cv[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:784\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    783\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:880\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    873\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[0;32m    874\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[0;32m    875\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    876\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[0;32m    877\u001b[0m         )\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 880\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 490\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \n\u001b[0;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf_grid = GridSearchCV(GradientBoostingRegressor(min_samples_split = 2, min_samples_leaf = 1), param_grid={'n_estimators': [100, 150]})\n",
    "do_cross_validation(clf_grid, print_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_TRIALS):\n",
    "    # Choose cross-validation techniques for the inner and outer loops\n",
    "    inner_cv = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True, random_state=i)\n",
    "\n",
    "   #Y is continuous\n",
    "    print(\"Labels unique values:\", np.unique(y))\n",
    "    print(\"Labels data type:\", y.dtype)\n",
    "\n",
    "    \n",
    "\n",
    "    # Non-nested parameter search and scoring\n",
    "    try:\n",
    "        clf_non_nested = GradientBoostingRegressor(\n",
    "            n_estimators=150,  # number of boosting stages to be run\n",
    "            max_depth= 4,  # maximum depth of each tree\n",
    "            min_samples_split=2,  # minimum samples required to split an internal node\n",
    "            min_samples_leaf=1  # minimum samples required to be at a leaf node\n",
    "        )\n",
    "        clf_non_nested.fit(X, y)\n",
    "        non_nested_scores[i] = clf_non_nested.best_score_\n",
    "    except ValueError as e:\n",
    "        print(f\"Non-nested CV error: {e}\")\n",
    "        non_nested_scores[i] = np.nan  # Set to NaN in case of error\n",
    "        \n",
    "    \n",
    "    #clf_nested = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv, error_score='raise')\n",
    "    #nested_score = cross_val_score(clf_nested, X=X, y=y, cv=outer_cv)\n",
    "    #nested_scores[i] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 3\n",
    "for i in range(NUM_TRIALS):\n",
    "    # Choose cross-validation techniques for the inner and outer loops\n",
    "    inner_cv = KFold(n_splits=3, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=3, shuffle=True, random_state=i)\n",
    "\n",
    "    # Y is continuous\n",
    "    print(\"Labels unique values:\", np.unique(y))\n",
    "    print(\"Labels data type:\", y.dtype)\n",
    "\n",
    "    # Non-nested parameter search and scoring\n",
    "    try:\n",
    "        clf_non_nested = GradientBoostingRegressor(\n",
    "            n_estimators=150,  # number of boosting stages to be run\n",
    "            max_depth=4,  # maximum depth of each tree\n",
    "            min_samples_split=2,  # minimum samples required to split an internal node\n",
    "            min_samples_leaf=1  # minimum samples required to be at a leaf node\n",
    "        )\n",
    "        clf_non_nested.fit(X, y)\n",
    "\n",
    "       \n",
    "        y_pred = clf_non_nested.predict(X)\n",
    "        non_nested_scores[i] = mean_squared_error(y, y_pred)\n",
    "    except ValueError as e:\n",
    "        print(f\"Non-nested CV error: {e}\")\n",
    "        non_nested_scores[i] = np.nan\n",
    "\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39mcv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Fit GridSearchCV to the data\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Get the best parameters and best score\u001b[39;00m\n\u001b[0;32m     26\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "\n",
    "# Define the model\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],  # Number of boosting stages\n",
    "    'max_depth': [3, 4, 5],  # Maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'learning_rate': [0.01, 0.05, 0.1]  # Learning rate shrinks the contribution of each tree\n",
    "}\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define GridSearchCV with the model and parameter grid\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV to the data\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best parameters found: \", best_params)\n",
    "print(\"Best cross-validation score: \", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done fr now\n"
     ]
    }
   ],
   "source": [
    "print('done fr now')\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
